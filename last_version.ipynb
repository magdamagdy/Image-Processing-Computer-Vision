{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magdamagdy/Image-Processing-Computer-Vision/blob/main/last_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports"
      ],
      "metadata": {
        "id": "OXListP2x9Zq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jUAiu5Otp2Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ef6efa-bc2a-4a07-df19-93d7a0ccea3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2580480/45929032 bytes (5.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6119424/45929032 bytes (13.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9756672/45929032 bytes (21.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13008896/45929032 bytes (28.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16629760/45929032 bytes (36.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20250624/45929032 bytes (44.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23863296/45929032 bytes (52.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27451392/45929032 bytes (59.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31154176/45929032 bytes (67.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34627584/45929032 bytes (75.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38281216/45929032 bytes (83.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41967616/45929032 bytes (91.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45744128/45929032 bytes (99.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yfTK_PiQ_gar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12739e72-178f-458a-e2b9-c4127a9418a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP5eBZPlOquO"
      },
      "source": [
        "## functions to show and plt images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jMOSBFno98Ph"
      },
      "outputs": [],
      "source": [
        "def show_image (image, title= \"Image\", cmap_type ='gray'): #define func to take the image and plot it  \n",
        "  plt.imshow(image, cmap_type)\n",
        "  plt.title(title)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7stBYIL6tU6o"
      },
      "outputs": [],
      "source": [
        "def plt_images(orig_image, orig_title, processed_image, processed_title, cmap='gray'):\n",
        "    # Visualize undirstorsion\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 70))\n",
        "    ax1.set_title(orig_title, fontsize=30)\n",
        "    ax1.imshow(orig_image)\n",
        "    ax2.set_title(processed_title, fontsize=30)\n",
        "    ax2.imshow(processed_image, cmap='gray')\n",
        "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js3K-0dTOmoP"
      },
      "source": [
        "## canny fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9bDTrBn1t38p"
      },
      "outputs": [],
      "source": [
        "#this fn gets canny edges for s channel of the original image and return binary image\n",
        "def canny(img):\n",
        "      # Convert to HLS color space to use s_channel as it will give better effect in sunny regions \n",
        "      hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
        "      l_channel = hls[:,:,1]  \n",
        "      s_channel = hls[:,:,2]\n",
        "      h_channel = hls[:,:,0]\n",
        "      canny_edges = cv2.Canny(s_channel,50,150)\n",
        "      canny_binary = np.zeros_like(canny_edges)\n",
        "      canny_binary[(canny_edges==255 )] = 1\n",
        "      return canny_binary\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDLARzI7N8yc"
      },
      "source": [
        "## warp and inv_warp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Drqk0W2AGZXY"
      },
      "outputs": [],
      "source": [
        "def perspective_warp(img, \n",
        "                     dst_size=(1280,720),\n",
        "                     src=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]),#[(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)] [(0.30,0.65),(0.60,0.65),(0.1,1),(1,1)]\n",
        "                     dst=np.float32([(0,0), (1, 0), (0,1), (1,1)])):\n",
        "    img_size = np.float32([(img.shape[1],img.shape[0])])\n",
        "    src = src* img_size\n",
        "    # For destination points, I'm arbitrarily choosing some points to be a nice fit for displaying our warped result again, not exact, but close enough for our purposes\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    # Given src and dst points, calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    # Warp the image using OpenCV warpPerspective()\n",
        "    warped = cv2.warpPerspective(img, M, dst_size,cv2.INTER_LINEAR)\n",
        "    return warped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "27H0_tQZ0GE4"
      },
      "outputs": [],
      "source": [
        "def inv_perspective_warp(img, \n",
        "                     dst_size=(1280,720),\n",
        "                     src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
        "                     dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)])):#[(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)] [(0.30,0.65),(0.60,0.65),(0.1,1),(1,1)]\n",
        "    img_size = np.float32([(img.shape[1],img.shape[0])])\n",
        "    src = src* img_size\n",
        "    # For destination points, I'm arbitrarily choosing some points to be\n",
        "    # a nice fit for displaying our warped result \n",
        "    # again, not exact, but close enough for our purposes\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    # Given src and dst points, calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    # Warp the image using OpenCV warpPerspective()\n",
        "    warped = cv2.warpPerspective(img, M, dst_size,cv2.INTER_LINEAR)\n",
        "    return warped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtDHEimfQUbE"
      },
      "source": [
        "## draw rectangle before and after warping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i1696wtIQckF"
      },
      "outputs": [],
      "source": [
        "def Draw_rectangle(warped_img):\n",
        "  rect = np.dstack((warped_img, warped_img, warped_img))*255  #warped_img is binary 1 channel so we convert it to colored mage 3 channels so we can draw colored rectangl on it\n",
        "  # rect = np.ones_like(Final_warp)\n",
        "  rect = cv2.rectangle(rect,(70,0),(1220,720),(255,0,0),20)  #to draw rect you need top-left corner and bottom-right corner of rectangle\n",
        "  # test =cv2.add(Final_warp,rect)\n",
        "  #bitwiseOr = cv2.bitwise_or(rect, Final_warp)\n",
        "  return rect #return rectangle or rect??????????????? rect:return the warped image with the rectangle drawing on it"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_with_rectangle(rect,after_warp):\n",
        "  Rectangle = cv2.add(rect,after_warp, dtype = cv2.CV_8U)\n",
        "  return Rectangle"
      ],
      "metadata": {
        "id": "-3ZESSaFnUST"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8dwP5k-hnxk"
      },
      "source": [
        "## window sliding "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB9bk69152tg"
      },
      "source": [
        "## find lane pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cHVEvi3heoo1"
      },
      "outputs": [],
      "source": [
        "def find_lane_pixels(image): #image --> after warping image\n",
        "    histogram = np.sum(image[image.shape[0] // 2:, :], axis=0)\n",
        "    out_img = np.dstack((image, image, image)) * 255 #input image is 1 channel so convert it to 3 channel\n",
        "    # out_img will be the warped image with the sliding window on it \n",
        "    midpoint = np.int(histogram.shape[0] // 2) # get midpoint of histogram\n",
        "    leftx_base = np.argmax(histogram[:midpoint]) # get index of peak in the first half of histogram which will correspond to the position of left lane\n",
        "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint # get index of peak in the second half of histogram which will correspond to the position of right lane\n",
        "\n",
        "    # plt.title('Histogram', fontsize=16)\n",
        "    # plt.xlabel('Pixel position')\n",
        "    # plt.ylabel('Counts')\n",
        "    # plt.plot(histogram);\n",
        "\n",
        "    nwindows = 9 # no of windows \n",
        "    margin = 100 # width of window /2\n",
        "    minpix = 50 #?????????????????????????????????????????????????????????????????????????????????????\n",
        "\n",
        "    window_height = np.int(image.shape[0] // nwindows) # get window_height by dividing the image height / nwindows\n",
        "    # print(\"image:\",image)\n",
        "    # nonzero(): Return : [tuple_of_arrays] Indices of elements that are non-zero\n",
        "    nonzero = image.nonzero()        # to get the location of nonzero pixels in image\n",
        "    # print(\"image.nonzero: \",nonzero)\n",
        "    # [[0,5,0,0,1],\n",
        "    # [0,0,0,0,0],\n",
        "    # [4,7,-3,0,0]]\n",
        "    nonzeroy = np.array(nonzero[0])  # to get the rows that have non zero           [0,0,2,2,2]\n",
        "    nonzerox = np.array(nonzero[1])  # to get the index of each non zero element    [1,4,0,1,2]\n",
        "    # print(\"nonzeroy: \",nonzero[0])\n",
        "    # print(\"nonzerox: \",nonzero[1])\n",
        "\n",
        "    # let the start point for window sliding is @ the 2 peaks of histogram\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "\n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "\n",
        "    for window in range(nwindows):\n",
        "        #first window\n",
        "        # Identify window boundaries in x and y (and right and left)\n",
        "        win_y_low = image.shape[0] - (window + 1) * window_height  # y of top edge of window\n",
        "        win_y_high = image.shape[0] - window * window_height       # y of bottom edge of window\n",
        "        win_xleft_low = leftx_current - margin                     # x of left edge of left window\n",
        "        win_xleft_high = leftx_current + margin                    # x of right edge of left window\n",
        "        win_xright_low = rightx_current - margin                   # x of left edge of right window\n",
        "        win_xright_high = rightx_current + margin                  # x of right edge of right window\n",
        "\n",
        "        # Draw the windows on the visualization image\n",
        "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 4)\n",
        "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 4)\n",
        "\n",
        "        # Identify the nonzero pixels in x and y within the window ###\n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        #good_left_inds -> array contain indices of non zero values inside the left window region\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
        "        #good_right_inds -> array contain indices of non zero values inside the right window region\n",
        "        # Append these indices to the lists\n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "\n",
        "        # If you found > minpix pixels, recenter next window on their mean position\n",
        "        if len(good_left_inds) > minpix:#>\n",
        "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:#>\n",
        "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
        "    try:\n",
        "        left_lane_inds = np.concatenate(left_lane_inds)\n",
        "        right_lane_inds = np.concatenate(right_lane_inds)\n",
        "    except ValueError:\n",
        "        # Avoids an error if the above is not implemented fully\n",
        "        pass\n",
        "\n",
        "    # Extract left and right line pixel positions\n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "    return leftx, lefty, rightx, righty, out_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E55SYwS559Yz"
      },
      "source": [
        "## fit_poly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f-HlRNT05rTb"
      },
      "outputs": [],
      "source": [
        "# Fit a poly to perform a directed search in well known areas\n",
        "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
        "    # Fit a second order polynomial to each with np.polyfit()\n",
        "    left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    right_fit = np.polyfit(righty, rightx, 2)\n",
        "    # Generate x and y values for plotting\n",
        "    ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])# Y values:[0:h-1] , number of samples = h\n",
        "    # Calc both polynomials using ploty, left_fit and right_fit\n",
        "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]# aY^2 +bY+c\n",
        "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]# aY^2 +bY+c\n",
        "\n",
        "    return left_fitx, right_fitx, ploty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5OS7Mmf6BcR"
      },
      "source": [
        "## search around poly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eXvrbvid5w4T"
      },
      "outputs": [],
      "source": [
        "def search_around_poly(image):\n",
        "    margin = 100\n",
        "\n",
        "    # Grab activated pixels\n",
        "    nonzero = image.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "\n",
        "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(image)\n",
        "###############################################\n",
        "    window_img = np.copy(out_img)\n",
        "    filled_lanes_img = np.copy(out_img) \n",
        "    if ((len(leftx) == 0) or (len(rightx) == 0) or (len(righty) == 0) or (len(lefty) == 0)):   ####### msh fahmin #########\n",
        "        out_img = np.dstack((image, image, image)) * 255\n",
        "        left_curverad = 0\n",
        "        right_curverad = 0\n",
        "        center_diff =0\n",
        "    else:\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "        ### Set the area of search based on activated x-values ###\n",
        "        ### within the +/- margin of our polynomial function ###\n",
        "        left_lane_inds = ((nonzerox > (left_fit[0] * (nonzeroy ** 2) + left_fit[1] * nonzeroy +\n",
        "                                       left_fit[2] - margin)) & (nonzerox < (left_fit[0] * (nonzeroy ** 2) +\n",
        "                                                                             left_fit[1] * nonzeroy + left_fit[\n",
        "                                                                                 2] + margin)))\n",
        "        right_lane_inds = ((nonzerox > (right_fit[0] * (nonzeroy ** 2) + right_fit[1] * nonzeroy +\n",
        "                                        right_fit[2] - margin)) & (nonzerox < (right_fit[0] * (nonzeroy ** 2) +\n",
        "                                                                               right_fit[1] * nonzeroy + right_fit[\n",
        "                                                                                   2] + margin)))\n",
        "\n",
        "        # Again, extract left and right line pixel positions\n",
        "        leftx = nonzerox[left_lane_inds]\n",
        "        lefty = nonzeroy[left_lane_inds]\n",
        "        rightx = nonzerox[right_lane_inds]\n",
        "        righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "        # Fit new polynomials\n",
        "        left_fitx, right_fitx, ploty = fit_poly(image.shape, leftx, lefty, rightx, righty)\n",
        "\n",
        "\n",
        "        ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
        "        xm_per_pix = 3 / 500  # meters per pixel in x dimension\n",
        "        # xm_per_pix = 3.7 / 650  # meters per pixel in x dimension\n",
        "        # xm_per_pix = 3.7/730 # meters per pixel in x dimension\n",
        "        # xm_per_pix = 3.7/960 # meters per pixel in x dimension\n",
        "        # Calculate the curvature radii\n",
        "        left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2) #left_fit_circle\n",
        "        right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
        "        y_eval = np.max(ploty)\n",
        "        left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
        "            2 * left_fit_cr[0])\n",
        "        right_curverad = ((1 + (\n",
        "                    2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
        "            2 * right_fit_cr[0])\n",
        "                    \n",
        "#################### added to calculate center offset ##########################################\n",
        "        camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
        "        center_diff = (camera_center-image.shape[1]/2)*xm_per_pix\n",
        "\n",
        "        ## Visualization ##\n",
        "        # Create an image to draw on and an image to show the selection window\n",
        "        out_img = np.dstack((image, image, image)) * 255\n",
        "        # window_img = np.zeros_like(out_img)\n",
        "#######################################################################################\n",
        "# we need to draw two lanes by fitting 2 line through the points\n",
        "        # Color in left and right line pixels\n",
        "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
        "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
        "        #image = cv2.polylines(image, [pts], False, (0,255,0), 10)\n",
        "        # x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0]) \n",
        "        # y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0]) \n",
        "        # z = np.polyfit(x, y, 2)\n",
        "####################################################################################### \n",
        "        filled_lanes_img = np.copy(out_img) \n",
        "\n",
        "        # Generate and draw a poly to illustrate the lane area\n",
        "        left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "        right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "        points = np.hstack((left, right))\n",
        "        out_img = cv2.fillPoly(out_img, np.int_(points), (0, 255, 255))\n",
        "        \n",
        "        #out img is the warped image with the lanes on it left(red) right(blue)\n",
        "    return out_img, window_img, filled_lanes_img, left_curverad, right_curverad,center_diff\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujhl6bmYv5VP"
      },
      "source": [
        "## region of interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aHvFVXrtv-Q0"
      },
      "outputs": [],
      "source": [
        "def region_of_interest(img):\n",
        "  h=img.shape[0]\n",
        "  w=img.shape[1]\n",
        "  # polygons = np.array([[100,h],[400,570],[600,530],[750,500],[870,530],[1200,h]])\n",
        "  polygons = np.array([[30,h],[w,h],[w,0],[1300,0],[630,460],[480,500]])\n",
        "  #  [(100,height),(480,int(height/2)),(900,height)] 3/5 2/3 \n",
        "  #  [(0,h),(int(0.1*w),int(h* 2/3)),(int(0.8*w),int(h* 2/3)),(int(0.9*w),h)] \n",
        "  #  [200,h],[600,700],[700,650],[1020,600],[1200,800],[1400,h]\n",
        "  #  [100,h],[400,570],[600,530],[750,450],[870,530],[1200,h]\n",
        "  mask=np.zeros_like(img)\n",
        "  cv2.fillPoly(mask,pts=[polygons],color=(255,255,255))\n",
        "  masked_image = cv2.bitwise_and(mask,img)\n",
        "  return masked_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeMTikUFiZ5O"
      },
      "source": [
        "## crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EU5w-UOvidTd"
      },
      "outputs": [],
      "source": [
        "def crop(img):\n",
        "  h=img.shape[0]\n",
        "  w=img.shape[1]\n",
        "  polygons = np.array([[(130,h),(w,h),(w,0),(130,0)]])#[(100,height),(480,int(height/2)),(900,height)]\n",
        "  mask=np.zeros_like(img)\n",
        "  cv2.fillPoly(mask,polygons,255)\n",
        "  masked_image = cv2.bitwise_and(mask,img)\n",
        "  return masked_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69TyzE1U401"
      },
      "source": [
        "## remove_shadow_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dG0Q43K3VDaO"
      },
      "outputs": [],
      "source": [
        "def remove_noise(img):\n",
        "    h=img.shape[0]\n",
        "    w=img.shape[1]\n",
        "    half_w=int(w/2)\n",
        "    polygons = np.array([[(half_w-300,h),(half_w+375,h),(half_w+380,0),(half_w-280,0)]]) #250\n",
        "    mask=np.ones_like(img)\n",
        "    cv2.fillPoly(mask,polygons,0)\n",
        "    masked_image = cv2.bitwise_and(mask,img)\n",
        "    return masked_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urSH_0guerZu"
      },
      "source": [
        "## threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-KpnQ6gbepdd"
      },
      "outputs": [],
      "source": [
        "def threshold_rel(img, lo, hi):\n",
        "  vmin = np.min(img)\n",
        "  # print(\"vmin = \", vmin)\n",
        "  vmax = np.max(img)\n",
        "  # print(\"vmax = \", vmax)\n",
        "  vlo = vmin + (vmax - vmin) * lo\n",
        "  # print(\"vlo = \", vlo)\n",
        "  vhi = vmin + (vmax - vmin) * hi\n",
        "  # print(\"vhi = \", vhi)\n",
        "  # print(np.uint8((img >= vlo) & (img <= vhi)) * 255)\n",
        "  return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
        "\n",
        "def threshold_abs(img, lo, hi):\n",
        "  # print(np.uint8((img >= lo) & (img <= hi)) * 255)\n",
        "  return np.uint8((img >= lo) & (img <= hi)) * 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuu-h9gVZ3Oq"
      },
      "source": [
        "## combinesd thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "whUZuMpZZ6vX"
      },
      "outputs": [],
      "source": [
        "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    isX = 1 if orient == 'x' else 0\n",
        "    sobel = cv2.Sobel(gray, cv2.CV_64F, isX, 1-isX)\n",
        "    abs_sobel = np.absolute(sobel)\n",
        "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel)) \n",
        "    grad_binary = np.zeros_like(scaled_sobel)\n",
        "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
        "    return grad_binary\n",
        "\n",
        "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
        "    abs_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
        "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel)) \n",
        "    mag_binary = np.zeros_like(scaled_sobel)\n",
        "    mag_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
        "    return mag_binary\n",
        "\n",
        "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
        "    abs_sobelx = np.absolute(sobelx)\n",
        "    abs_sobely = np.absolute(sobely)\n",
        "    grad_dir = np.arctan2(abs_sobely, abs_sobelx)\n",
        "    dir_binary = np.zeros_like(grad_dir)\n",
        "    dir_binary[(grad_dir >= thresh[0]) & (grad_dir <= thresh[1])] = 1\n",
        "    return dir_binary\n",
        "\n",
        "def apply_thresholds(image, ksize=3):\n",
        "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(10, 100))#(20, 100)\n",
        "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(10, 100))\n",
        "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
        "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
        "\n",
        "    combined = np.zeros_like(dir_binary)\n",
        "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
        "    \n",
        "    return combined\n",
        "\n",
        "\n",
        "def apply_color_threshold(image):\n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "    s_channel = hls[:,:,2]\n",
        "    s_thresh_min = 170\n",
        "    s_thresh_max = 255\n",
        "    s_binary = np.zeros_like(s_channel)\n",
        "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
        "    return s_binary\n",
        "\n",
        "\n",
        "def combine_threshold(s_binary, combined):\n",
        "    combined_binary = np.zeros_like(combined)\n",
        "    combined_binary[(s_binary == 1) |(s_binary == 255) | (combined == 1) |(combined == 255)] = 1\n",
        "    return combined_binary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_jYEY-jftqV"
      },
      "source": [
        "## cocatenate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e_RzjyLTfy4m"
      },
      "outputs": [],
      "source": [
        "\n",
        "def combine_images( lane_area_img1, edges, warp,warp_rect,warp_highlight, lane):        \n",
        "        \n",
        "        background = np.zeros_like(lane_area_img1)\n",
        "        large_img_size = (background.shape[1] - int(background.shape[1]/3),int(0.75*background.shape[0])) \n",
        "        small_img_size=(int(background.shape[1]/3),int(0.25*background.shape[0]))\n",
        "        small_img_x_offset=0 \n",
        "        small_img_y_offset=0\n",
        "        x=int((0.75*background.shape[0])/2)\n",
        "        new_image=(int(background.shape[1]/3),x)\n",
        "\n",
        "        warp_img = cv2.resize(np.dstack((warp, warp, warp))*255,small_img_size)\n",
        "        edges_image = cv2.resize(np.dstack((edges, edges, edges))*255,small_img_size)\n",
        "        lane_img = cv2.resize(lane,new_image)\n",
        "        road = cv2.resize(lane_area_img1,large_img_size)\n",
        "        warp_rect_img = cv2.resize(warp_rect,small_img_size)\n",
        "        warp_highlight_img = cv2.resize(warp_highlight,new_image)\n",
        "\n",
        "        background[0: small_img_size[1], 0: small_img_size[0]] = edges_image\n",
        "        \n",
        "        start_offset_y = small_img_y_offset \n",
        "        endy = start_offset_y + small_img_size[1]\n",
        "        if endy > background.shape[0]:\n",
        "          endy = background.shape[0]\n",
        "        start_offset_x = 2 * small_img_x_offset + small_img_size[0]\n",
        "        endx = start_offset_x + small_img_size[0]\n",
        "        if endx > background.shape[1]:\n",
        "          endx = background.shape[1]\n",
        "        background[start_offset_y:endy , start_offset_x: endx] = warp_img\n",
        "        \n",
        "        start_offset_y = small_img_y_offset \n",
        "        endy = start_offset_y + small_img_size[1]\n",
        "        if endy > background.shape[0]:\n",
        "          endy = background.shape[0]\n",
        "        start_offset_x = 3 * small_img_x_offset + 2 * small_img_size[0]\n",
        "        endx = start_offset_x + small_img_size[0]\n",
        "        if endx > background.shape[1]:\n",
        "          endx = background.shape[1]\n",
        "        background[start_offset_y: endy, start_offset_x: endx] = warp_rect_img\n",
        "\n",
        "        start_offset_y = small_img_y_offset \n",
        "        endy = x +int(0.25*background.shape[0])\n",
        "        if endy > background.shape[0]:\n",
        "          endy = background.shape[0]\n",
        "        # start_offset_x = 3 * small_img_x_offset + 3 * small_img_size[0]\n",
        "        # endx = start_offset_x + small_img_size[0]\n",
        "        if endx > background.shape[1]:\n",
        "          endx = background.shape[1]\n",
        "        background[int(0.25*background.shape[0]): endy, background.shape[1] - int(background.shape[1]/3): ] = warp_highlight_img\n",
        "\n",
        "        # start_offset_y = small_img_y_offset \n",
        "        # endy = int(0.25*background.shape[0]) + 2*small_img_size[1]\n",
        "        # if endy > background.shape[0]:\n",
        "        #   endy = background.shape[0]\n",
        "        # start_offset_x = 3 * small_img_x_offset + 3 * small_img_size[0]\n",
        "        # endx = start_offset_x + small_img_size[0]\n",
        "        # if endx > background.shape[1]:\n",
        "        #   endx = background.shape[1]\n",
        "        background[endy: , background.shape[1] - int(background.shape[1]/3): ] = lane_img\n",
        "\n",
        "\n",
        "        # start_offset_y = small_img_y_offset \n",
        "        # start_offset_x = 4 * small_img_x_offset + 3 * small_img_size[0]\n",
        "        background[int(0.25*background.shape[0]):  , 0:background.shape[1] - int(background.shape[1]/3)  ] = road\n",
        "        \n",
        "        \n",
        "        return background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4_JK_tHeDqK"
      },
      "source": [
        "## process7_debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5B8QISXkeIDy"
      },
      "outputs": [],
      "source": [
        "def process7_debug(input):\n",
        " \n",
        "    # step 1 get edges\n",
        "    # after_thr=thresholding(input)\n",
        "    # after_canny=canny(input)\n",
        "    # combined = combine_threshold(after_thr,after_canny)\n",
        "    # region_of_inter = region_of_interest(input)\n",
        "\n",
        "    after_canny=canny(input)\n",
        "    # plt_images(input,\"input\",after_canny,\"after canny\")\n",
        "\n",
        "    blur = cv2.blur(input,(5,5))\n",
        "\n",
        "    gradient_combined = apply_thresholds(blur) #input\n",
        "    # Color thresholding\n",
        "    s_binary = apply_color_threshold(blur) #input\n",
        "    # Combine Gradient and Color thresholding\n",
        "    combined_binary = combine_threshold(s_binary, gradient_combined)\n",
        "\n",
        "    combined = combine_threshold(after_canny,combined_binary)\n",
        "    # plt_images(input,\"input\",after_canny,\"after canny\")\n",
        "\n",
        "    ##############################################\n",
        "    # show after canny+,  combined_binary,  combined, after warp+, paint, rect, inv_rect, result+\n",
        "\n",
        "    # step 2 warp canny image\n",
        "    after_warp1=perspective_warp(combined)\n",
        "    # after_warp1=strong_warp(after_warp1)\n",
        "    # plt_images(after_canny,\"after canny\",after_warp,\"after warp\")\n",
        "    after_warp = remove_noise(after_warp1)\n",
        "    rect = Draw_rectangle(after_warp)#take 1 channel img\n",
        "    # rect = img_with_rectangle(rect1,after_warp)\n",
        "    # # rect_img=cv2.add(rect,after_warp,dtype = cv2.CV_8U)\n",
        "    inv_rect =inv_perspective_warp(rect) \n",
        "\n",
        "    # step 3 paint area between lanes\n",
        "    # out_img, window_img, filled_lanes_img, left_curverad, right_curverad\n",
        "    paint,window_img,filled_lanes_img, left_curverad, right_curverad, center_diff = search_around_poly(after_warp)\n",
        "    # plt_images(after_warp,\"after warp\",filled_lanes_img,\"filled lanes\")\n",
        "    # plt_images(window_img,\"window img\",paint,\" painted area \")\n",
        "\n",
        "\n",
        "    # step 4 inverse perspective\n",
        "    frame =inv_perspective_warp(paint, \n",
        "                        dst_size=(input.shape[1],input.shape[0]),\n",
        "                        src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
        "                        dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]))\n",
        "\n",
        "\n",
        "    # step 5 add painting to input image\n",
        "    result = cv2.addWeighted(frame, 0.3, input, 0.7, 0,dtype = cv2.CV_8U) \n",
        "    # plt_images(input, ' input ', result, ' result ')\n",
        "    # iny = process_image_rect(input)\n",
        "    # print(\"combined: \",combined.shape,combined)\n",
        "    # print(\"after_warp: \",after_warp.shape,after_warp)\n",
        "    curverad= (left_curverad + right_curverad)/2\n",
        "    side_pos = 'right'\n",
        "    if center_diff <= 0:\n",
        "        side_pos = 'left'\n",
        "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "#combine_images( lane_area_img1(resul), edges(binary), warp(binary),warp_rect(rect),warp_highlight(paint), lane(inv_rect))\n",
        "    out = combine_images(result, combined, after_warp, rect, paint, inv_rect) # after_canny, after_warp,input must be binary\n",
        "    # cv2_imshow(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## process7_no_debug"
      ],
      "metadata": {
        "id": "hEN7_RiO2RSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process7(input):\n",
        " \n",
        "    # step 1 get edges\n",
        "    # after_thr=thresholding(input)\n",
        "    # after_canny=canny(input)\n",
        "    # combined = combine_threshold(after_thr,after_canny)\n",
        "    # region_of_inter = region_of_interest(input)\n",
        "\n",
        "    after_canny=canny(input)\n",
        "    # plt_images(input,\"input\",after_canny,\"after canny\")\n",
        "\n",
        "    blur = cv2.blur(input,(5,5))\n",
        "\n",
        "    gradient_combined = apply_thresholds(blur) #input\n",
        "    # Color thresholding\n",
        "    s_binary = apply_color_threshold(blur) #input\n",
        "    # Combine Gradient and Color thresholding\n",
        "    combined_binary = combine_threshold(s_binary, gradient_combined)\n",
        "\n",
        "    combined = combine_threshold(after_canny,combined_binary)\n",
        "    # plt_images(input,\"input\",after_canny,\"after canny\")\n",
        "    \n",
        "    # step 2 warp canny image\n",
        "    after_warp1=perspective_warp(combined)\n",
        "    # after_warp1=strong_warp(after_warp1)\n",
        "    # plt_images(after_canny,\"after canny\",after_warp,\"after warp\")\n",
        "    after_warp = remove_noise(after_warp1)\n",
        "    # rect = Draw_rectangle(after_warp)#take 1 channel img\n",
        "    # # rect_img=cv2.add(rect,after_warp,dtype = cv2.CV_8U)\n",
        "    # inv_rect =inv_perspective_warp(rect) \n",
        "\n",
        "    # step 3 paint area between lanes\n",
        "    # out_img, window_img, filled_lanes_img, left_curverad, right_curverad\n",
        "    paint,window_img,filled_lanes_img, left_curverad, right_curverad, center_diff = search_around_poly(after_warp)\n",
        "    # plt_images(after_warp,\"after warp\",filled_lanes_img,\"filled lanes\")\n",
        "    # plt_images(window_img,\"window img\",paint,\" painted area \")\n",
        "\n",
        "\n",
        "    # step 4 inverse perspective\n",
        "    frame =inv_perspective_warp(paint, \n",
        "                        dst_size=(input.shape[1],input.shape[0]),\n",
        "                        src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
        "                        dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]))\n",
        "\n",
        "\n",
        "    # step 5 add painting to input image\n",
        "    result = cv2.addWeighted(frame, 0.3, input, 0.7, 0,dtype = cv2.CV_8U) \n",
        "   \n",
        "    curverad= (left_curverad + right_curverad)/2\n",
        "    side_pos = 'right'\n",
        "    if center_diff <= 0:\n",
        "        side_pos = 'left'\n",
        "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "SWIYlUwx2Tmy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4v95VznclvF"
      },
      "source": [
        "## to process a video and save the output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_video(Input_video_path,Output_video_path,mode):\n",
        "  clip1 = VideoFileClip(Input_video_path)\n",
        "  if (mode==1):\n",
        "    video_clip = clip1.fl_image(process7_debug) \n",
        "    video_clip.write_videofile(Output_video_path, audio=False)\n",
        "  else:\n",
        "    video_clip = clip1.fl_image(process7) \n",
        "    video_clip.write_videofile(Output_video_path, audio=False)\n",
        "\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "qwG3CVS90-7a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Input_video_path=\"/content/drive/MyDrive/test_images/challenge_video.mp4\"#challenge_video\n",
        "Output_video_path='vid5.mp4'\n",
        "create_video(Input_video_path,Output_video_path,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNF94SSzRftb",
        "outputId": "866a8591-026f-4d3c-ba04-324b33837901"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] >>>> Building video vid5.mp4\n",
            "[MoviePy] Writing video vid5.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 485/485 [03:06<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: vid5.mp4 \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dP5eBZPlOquO",
        "Js3K-0dTOmoP",
        "kDLARzI7N8yc",
        "rtDHEimfQUbE",
        "S8dwP5k-hnxk",
        "EB9bk69152tg",
        "E55SYwS559Yz",
        "b5OS7Mmf6BcR",
        "Ujhl6bmYv5VP",
        "VeMTikUFiZ5O",
        "V69TyzE1U401",
        "urSH_0guerZu",
        "nuu-h9gVZ3Oq",
        "N_jYEY-jftqV",
        "n4_JK_tHeDqK",
        "hEN7_RiO2RSU"
      ],
      "name": "last version.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}