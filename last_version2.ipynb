{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXListP2x9Zq"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUAiu5Otp2Fe",
        "outputId": "307cee25-8b30-4ac9-9187-7e9cc0720cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2678784/45929032 bytes (5.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5496832/45929032 bytes (12.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8355840/45929032 bytes (18.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11157504/45929032 bytes (24.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14114816/45929032 bytes (30.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16982016/45929032 bytes (37.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19660800/45929032 bytes (42.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22552576/45929032 bytes (49.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25346048/45929032 bytes (55.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28237824/45929032 bytes (61.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31006720/45929032 bytes (67.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34480128/45929032 bytes (75.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37994496/45929032 bytes (82.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41631744/45929032 bytes (90.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45367296/45929032 bytes (98.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfTK_PiQ_gar",
        "outputId": "b61610cf-8ac2-4222-f450-d938cc1e6a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP5eBZPlOquO"
      },
      "source": [
        "## functions to show and plt images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMOSBFno98Ph"
      },
      "outputs": [],
      "source": [
        "def show_image (image, title= \"Image\", cmap_type ='gray'): #define func to take the image and plot it  \n",
        "  plt.imshow(image, cmap_type)\n",
        "  plt.title(title)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7stBYIL6tU6o"
      },
      "outputs": [],
      "source": [
        "def plt_images(orig_image, orig_title, processed_image, processed_title, cmap='gray'):\n",
        "    # Visualize undirstorsion\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 70))\n",
        "    ax1.set_title(orig_title, fontsize=30)\n",
        "    ax1.imshow(orig_image)\n",
        "    ax2.set_title(processed_title, fontsize=30)\n",
        "    ax2.imshow(processed_image, cmap='gray')\n",
        "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js3K-0dTOmoP"
      },
      "source": [
        "## canny fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bDTrBn1t38p"
      },
      "outputs": [],
      "source": [
        "#this fn gets canny edges for s channel of the original image and return binary image\n",
        "def canny(img):\n",
        "      # Convert to HLS color space to use s_channel as it will give better effect in sunny regions \n",
        "      hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
        "      l_channel = hls[:,:,1]  \n",
        "      s_channel = hls[:,:,2]\n",
        "      h_channel = hls[:,:,0]\n",
        "      canny_edges = cv2.Canny(s_channel,50,150)\n",
        "      canny_binary = np.zeros_like(canny_edges)\n",
        "      canny_binary[(canny_edges==255 )] = 1\n",
        "      return canny_binary\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDLARzI7N8yc"
      },
      "source": [
        "## warp and inv_warp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drqk0W2AGZXY"
      },
      "outputs": [],
      "source": [
        "def perspective_warp(img, \n",
        "                     dst_size=(1280,720),\n",
        "                     src=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]),#[(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)] [(0.30,0.65),(0.60,0.65),(0.1,1),(1,1)]\n",
        "                     dst=np.float32([(0,0), (1, 0), (0,1), (1,1)])):\n",
        "    img_size = np.float32([(img.shape[1],img.shape[0])])\n",
        "    src = src* img_size\n",
        "    # For destination points, I'm arbitrarily choosing some points to be a nice fit for displaying our warped result again, not exact, but close enough for our purposes\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    # Given src and dst points, calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    # Warp the image using OpenCV warpPerspective()\n",
        "    warped = cv2.warpPerspective(img, M, dst_size,cv2.INTER_LINEAR)\n",
        "    return warped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27H0_tQZ0GE4"
      },
      "outputs": [],
      "source": [
        "def inv_perspective_warp(img, \n",
        "                     dst_size=(1280,720),\n",
        "                     src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
        "                     dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)])):#[(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)] [(0.30,0.65),(0.60,0.65),(0.1,1),(1,1)]\n",
        "    img_size = np.float32([(img.shape[1],img.shape[0])])\n",
        "    src = src* img_size\n",
        "    # For destination points, I'm arbitrarily choosing some points to be\n",
        "    # a nice fit for displaying our warped result \n",
        "    # again, not exact, but close enough for our purposes\n",
        "    dst = dst * np.float32(dst_size)\n",
        "    # Given src and dst points, calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    # Warp the image using OpenCV warpPerspective()\n",
        "    warped = cv2.warpPerspective(img, M, dst_size,cv2.INTER_LINEAR)\n",
        "    return warped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtDHEimfQUbE"
      },
      "source": [
        "## draw rectangle before and after warping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1696wtIQckF"
      },
      "outputs": [],
      "source": [
        "def Draw_rectangle(warped_img):\n",
        "  rect = np.dstack((warped_img, warped_img, warped_img))*255  #warped_img is binary 1 channel so we convert it to colored mage 3 channels so we can draw colored rectangl on it\n",
        "  # rect = np.ones_like(Final_warp)\n",
        "  rect = cv2.rectangle(rect,(70,0),(1220,720),(255,0,0),20)  #to draw rect you need top-left corner and bottom-right corner of rectangle\n",
        "  # test =cv2.add(Final_warp,rect)\n",
        "  #bitwiseOr = cv2.bitwise_or(rect, Final_warp)\n",
        "  return rect #return rectangle or rect??????????????? rect:return the warped image with the rectangle drawing on it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3ZESSaFnUST"
      },
      "outputs": [],
      "source": [
        "def img_with_rectangle(rect,after_warp):\n",
        "  Rectangle = cv2.add(rect,after_warp, dtype = cv2.CV_8U)\n",
        "  return Rectangle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8dwP5k-hnxk"
      },
      "source": [
        "## window sliding "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKKLDatri8NQ"
      },
      "source": [
        "## tharwat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAY_OdA9i7CD"
      },
      "outputs": [],
      "source": [
        "def pixels_in_window(nonzerox,nonzeroy,center, margin, height):\n",
        "        \"\"\" Return all pixel that in a specific window\n",
        "        Parameters:\n",
        "            center (tuple): coordinate of the center of the window\n",
        "            margin (int): half width of the window\n",
        "            height (int): height of the window\n",
        "        Returns:\n",
        "            pixelx (np.array): x coordinates of pixels that lie inside the window\n",
        "            pixely (np.array): y coordinates of pixels that lie inside the window\n",
        "        \"\"\"\n",
        "        topleft = (center[0]-margin, center[1]-height//2)\n",
        "        bottomright = (center[0]+margin, center[1]+height//2)\n",
        "\n",
        "        condx = (topleft[0] <= nonzerox) & (nonzerox <= bottomright[0])\n",
        "        condy = (topleft[1] <= nonzeroy) & (nonzeroy <= bottomright[1])\n",
        "        return nonzerox[condx&condy], nonzeroy[condx&condy]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB9bk69152tg"
      },
      "source": [
        "## find lane pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHVEvi3heoo1"
      },
      "outputs": [],
      "source": [
        "def find_lane_pixels(image): #image --> after warping image\n",
        "    assert(len(image.shape) ==2)\n",
        "    histogram = np.sum(image[image.shape[0] // 2:, :], axis=0)\n",
        "    out_img = np.dstack((image, image, image)) * 255 #input image is 1 channel so convert it to 3 channel\n",
        "    # out_img will be the warped image with the sliding window on it \n",
        "    midpoint = np.int(histogram.shape[0] // 2) # get midpoint of histogram\n",
        "    leftx_base = np.argmax(histogram[:midpoint]) # get index of peak in the first half of histogram which will correspond to the position of left lane\n",
        "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint # get index of peak in the second half of histogram which will correspond to the position of right lane\n",
        "\n",
        "    nwindows = 9 # no of windows \n",
        "    margin = 100 # width of window /2\n",
        "    minpix = 50 \n",
        "\n",
        "    window_height = np.int(image.shape[0] // nwindows) # get window_height by dividing the image height / nwindows\n",
        "    # print(\"image:\",image)\n",
        "    # nonzero(): Return : [tuple_of_arrays] Indices of elements that are non-zero\n",
        "    nonzero = image.nonzero()        # to get the location of nonzero pixels in image\n",
        "    # print(\"image.nonzero: \",nonzero)\n",
        "    # [[0,5,0,0,1],\n",
        "    # [0,0,0,0,0],\n",
        "    # [4,7,-3,0,0]]\n",
        "    nonzeroy = np.array(nonzero[0])  # to get the rows that have non zero           [0,0,2,2,2]\n",
        "    nonzerox = np.array(nonzero[1])  # to get the index of each non zero element    [1,4,0,1,2]\n",
        "    # print(\"nonzeroy: \",nonzero[0])\n",
        "    # print(\"nonzerox: \",nonzero[1])\n",
        "\n",
        "    # let the start point for window sliding is @ the 2 peaks of histogram\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "    y_current = image.shape[0] + window_height//2\n",
        "\n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "    leftx=[] \n",
        "    lefty=[] \n",
        "    rightx=[] \n",
        "    righty=[]\n",
        "\n",
        "    for window in range(nwindows):\n",
        "        #first window\n",
        "        # Identify window boundaries in x and y (and right and left)\n",
        "        win_y_low = image.shape[0] - (window + 1) * window_height  # y of top edge of window\n",
        "        win_y_high = image.shape[0] - window * window_height       # y of bottom edge of window\n",
        "        win_xleft_low = leftx_current - margin                     # x of left edge of left window\n",
        "        win_xleft_high = leftx_current + margin                    # x of right edge of left window\n",
        "        win_xright_low = rightx_current - margin                   # x of left edge of right window\n",
        "        win_xright_high = rightx_current + margin                  # x of right edge of right window\n",
        "\n",
        "        # Draw the windows on the visualization image\n",
        "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 4)\n",
        "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 4)\n",
        "\n",
        "        # Identify the nonzero pixels in x and y within the window ###\n",
        "        # good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        # #good_left_inds -> array contain indices of non zero values inside the left window region\n",
        "        # good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
        "        # #good_right_inds -> array contain indices of non zero values inside the right window region\n",
        "        y_current -= window_height\n",
        "        center_left = (leftx_current, y_current)\n",
        "        center_right = (rightx_current, y_current)\n",
        "        good_left_x, good_left_y = pixels_in_window(nonzerox,nonzeroy,center_left, margin, window_height)\n",
        "        good_right_x, good_right_y = pixels_in_window(nonzerox,nonzeroy,center_right, margin, window_height)\n",
        "        leftx.extend(good_left_x)\n",
        "        lefty.extend(good_left_y)\n",
        "        rightx.extend(good_right_x)\n",
        "        righty.extend(good_right_y)\n",
        "\n",
        "        # Append these indices to the lists\n",
        "        # left_lane_inds.append(good_left_inds)\n",
        "        # right_lane_inds.append(good_right_inds)\n",
        "\n",
        "        # If you found > minpix pixels, recenter next window on their mean position\n",
        "        if len(good_left_x) > minpix:\n",
        "            leftx_current = np.int32(np.mean(good_left_x))\n",
        "        if len(good_right_x) > minpix:\n",
        "            rightx_current = np.int32(np.mean(good_right_x))\n",
        "\n",
        "\n",
        "        # if len(good_left_inds) > minpix:#>\n",
        "        #     leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
        "        # if len(good_right_inds) > minpix:#>\n",
        "        #     rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
        "    # try:\n",
        "    #     left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    #     right_lane_inds = np.concatenate(right_lane_inds)\n",
        "    # except ValueError:\n",
        "    #     # Avoids an error if the above is not implemented fully\n",
        "    #     pass\n",
        "\n",
        "    # # Extract left and right line pixel positions\n",
        "    # leftx = nonzerox[left_lane_inds]\n",
        "    # lefty = nonzeroy[left_lane_inds]\n",
        "    # rightx = nonzerox[right_lane_inds]\n",
        "    # righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "    return leftx, lefty, rightx, righty, out_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E55SYwS559Yz"
      },
      "source": [
        "## fit_poly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-HlRNT05rTb"
      },
      "outputs": [],
      "source": [
        "# Fit a poly to perform a directed search in well known areas\n",
        "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
        "    # Fit a second order polynomial to each with np.polyfit()\n",
        "    left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    right_fit = np.polyfit(righty, rightx, 2)\n",
        "    # Generate x and y values for plotting\n",
        "    ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])# Y values:[0:h-1] , number of samples = h\n",
        "    # Calc both polynomials using ploty, left_fit and right_fit\n",
        "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]# aY^2 +bY+c\n",
        "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]# aY^2 +bY+c\n",
        "\n",
        "    return left_fitx, right_fitx, ploty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5OS7Mmf6BcR"
      },
      "source": [
        "## search around poly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXvrbvid5w4T"
      },
      "outputs": [],
      "source": [
        "left_fit=[]\n",
        "right_fit=[]\n",
        "def search_around_poly(image):\n",
        "    margin = 100\n",
        "\n",
        "    # Grab activated pixels\n",
        "    nonzero = image.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "\n",
        "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(image)\n",
        "    colored_img=np.dstack((image, image, image))\n",
        "    if len(lefty) > 1500:\n",
        "      global left_fit\n",
        "      left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    if len(righty) > 1500:\n",
        "      global right_fit\n",
        "      right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "    # Generate x and y values for plotting\n",
        "    maxy = image.shape[0] - 1\n",
        "    miny = image.shape[0] // 3\n",
        "    \n",
        "    if len(lefty):\n",
        "        maxy = max(maxy, np.max(lefty))\n",
        "        miny = min(miny, np.min(lefty))\n",
        "\n",
        "    if len(righty):\n",
        "        maxy = max(maxy, np.max(righty))\n",
        "        miny = min(miny, np.min(righty))\n",
        "\n",
        "    ploty = np.linspace(miny, maxy, image.shape[0])\n",
        "\n",
        "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty +left_fit[2]\n",
        "    right_fitx =right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
        "\n",
        "    for i, y in enumerate(ploty):\n",
        "            l = int(left_fitx[i])\n",
        "            r = int(right_fitx[i])\n",
        "            y = int(y)\n",
        "            cv2.line( colored_img, (l, y), (r, y), (0, 255, 0))\n",
        "    left_curverad, right_curverad, pos=measure_curvature(left_fit,right_fit)\n",
        "# ###############################################\n",
        "#     window_img = np.copy(out_img)\n",
        "#     filled_lanes_img = np.copy(out_img) \n",
        "#     if ((len(leftx) == 0) or (len(rightx) == 0) or (len(righty) == 0) or (len(lefty) == 0)):  \n",
        "#         out_img = np.dstack((image, image, image)) * 255\n",
        "#         left_curverad = 0\n",
        "#         right_curverad = 0\n",
        "#         center_diff =0\n",
        "#     else:\n",
        "#         left_fit = np.polyfit(lefty, leftx, 2)\n",
        "#         right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "#         ### Set the area of search based on activated x-values ###\n",
        "#         ### within the +/- margin of our polynomial function ###\n",
        "#         left_lane_inds = ((nonzerox > (left_fit[0] * (nonzeroy ** 2) + left_fit[1] * nonzeroy +\n",
        "#                                        left_fit[2] - margin)) & (nonzerox < (left_fit[0] * (nonzeroy ** 2) +\n",
        "#                                                                              left_fit[1] * nonzeroy + left_fit[\n",
        "#                                                                                  2] + margin)))\n",
        "#         right_lane_inds = ((nonzerox > (right_fit[0] * (nonzeroy ** 2) + right_fit[1] * nonzeroy +\n",
        "#                                         right_fit[2] - margin)) & (nonzerox < (right_fit[0] * (nonzeroy ** 2) +\n",
        "#                                                                                right_fit[1] * nonzeroy + right_fit[\n",
        "#                                                                                    2] + margin)))\n",
        "\n",
        "#         # Again, extract left and right line pixel positions\n",
        "#         leftx = nonzerox[left_lane_inds]\n",
        "#         lefty = nonzeroy[left_lane_inds]\n",
        "#         rightx = nonzerox[right_lane_inds]\n",
        "#         righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "#         # Fit new polynomials\n",
        "#         left_fitx, right_fitx, ploty = fit_poly(image.shape, leftx, lefty, rightx, righty)\n",
        "\n",
        "\n",
        "#         ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
        "#         xm_per_pix = 3 / 500  # meters per pixel in x dimension\n",
        "\n",
        "#         # Calculate the curvature radii\n",
        "#         left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2) #left_fit_circle\n",
        "#         right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
        "#         y_eval = np.max(ploty)\n",
        "#         left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
        "#             2 * left_fit_cr[0])\n",
        "#         right_curverad = ((1 + (\n",
        "#                     2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
        "#             2 * right_fit_cr[0])\n",
        "                    \n",
        "# #################### added to calculate center offset ##########################################\n",
        "#         camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
        "#         center_diff = (camera_center-image.shape[1]/2)*xm_per_pix\n",
        "\n",
        "#         ## Visualization ##\n",
        "#         # Create an image to draw on and an image to show the selection window\n",
        "#         out_img = np.dstack((image, image, image)) * 255\n",
        "#         # window_img = np.zeros_like(out_img)\n",
        "# #######################################################################################\n",
        "# # we need to draw two lanes by fitting 2 line through the points\n",
        "#         # Color in left and right line pixels\n",
        "#         out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
        "#         out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
        "\n",
        "# ####################################################################################### \n",
        "#         filled_lanes_img = np.copy(out_img) \n",
        "\n",
        "#         # Generate and draw a poly to illustrate the lane area\n",
        "#         left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "#         right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "#         points = np.hstack((left, right))\n",
        "#         out_img = cv2.fillPoly(out_img, np.int_(points), (0, 255, 255))\n",
        "        \n",
        "#         #out img is the warped image with the lanes on it left(red) right(blue)\n",
        "#    return out_img, window_img, filled_lanes_img, left_curverad, right_curverad,center_diff\n",
        "    return colored_img,left_curverad, right_curverad,pos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-oSGu3czQwO"
      },
      "outputs": [],
      "source": [
        "def measure_curvature(left_fit,right_fit):\n",
        "        ym = 30/720\n",
        "        xm = 3.7/700\n",
        "\n",
        "        left_fit = left_fit.copy()\n",
        "        right_fit = right_fit.copy()\n",
        "        y_eval = 700 * ym\n",
        "\n",
        "        # Compute R_curve (radius of curvature)\n",
        "        left_curveR =  ((1 + (2*left_fit[0] *y_eval + left_fit[1])**2)**1.5)  / np.absolute(2*left_fit[0])\n",
        "        right_curveR = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
        "\n",
        "        xl = np.dot(left_fit, [700**2, 700, 1])\n",
        "        xr = np.dot(right_fit, [700**2, 700, 1])\n",
        "        pos = (1280//2 - (xl+xr)//2)*xm\n",
        "        return left_curveR, right_curveR, pos "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujhl6bmYv5VP"
      },
      "source": [
        "## region of interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHvFVXrtv-Q0"
      },
      "outputs": [],
      "source": [
        "def region_of_interest(img):\n",
        "  h=img.shape[0]\n",
        "  w=img.shape[1]\n",
        "  # polygons = np.array([[100,h],[400,570],[600,530],[750,500],[870,530],[1200,h]])\n",
        "  polygons = np.array([[30,h],[w,h],[w,0],[1300,0],[630,460],[480,500]])\n",
        "  #  [(100,height),(480,int(height/2)),(900,height)] 3/5 2/3 \n",
        "  #  [(0,h),(int(0.1*w),int(h* 2/3)),(int(0.8*w),int(h* 2/3)),(int(0.9*w),h)] \n",
        "  #  [200,h],[600,700],[700,650],[1020,600],[1200,800],[1400,h]\n",
        "  #  [100,h],[400,570],[600,530],[750,450],[870,530],[1200,h]\n",
        "  mask=np.zeros_like(img)\n",
        "  cv2.fillPoly(mask,pts=[polygons],color=(255,255,255))\n",
        "  masked_image = cv2.bitwise_and(mask,img)\n",
        "  return masked_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeMTikUFiZ5O"
      },
      "source": [
        "## crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU5w-UOvidTd"
      },
      "outputs": [],
      "source": [
        "def crop(img):\n",
        "  h=img.shape[0]\n",
        "  w=img.shape[1]\n",
        "  polygons = np.array([[(130,h),(w,h),(w,0),(130,0)]])#[(100,height),(480,int(height/2)),(900,height)]\n",
        "  mask=np.zeros_like(img)\n",
        "  cv2.fillPoly(mask,polygons,255)\n",
        "  masked_image = cv2.bitwise_and(mask,img)\n",
        "  return masked_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69TyzE1U401"
      },
      "source": [
        "## remove_shadow_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG0Q43K3VDaO"
      },
      "outputs": [],
      "source": [
        "def remove_noise(img):\n",
        "    h=img.shape[0]\n",
        "    w=img.shape[1]\n",
        "    half_w=int(w/2)\n",
        "    polygons = np.array([[(half_w-300,h),(half_w+375,h),(half_w+380,0),(half_w-280,0)]]) \n",
        "    mask=np.ones_like(img)\n",
        "    cv2.fillPoly(mask,polygons,0)\n",
        "    masked_image = cv2.bitwise_and(mask,img)\n",
        "    return masked_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuu-h9gVZ3Oq"
      },
      "source": [
        "## combinesd thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whUZuMpZZ6vX"
      },
      "outputs": [],
      "source": [
        "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    isX = 1 if orient == 'x' else 0\n",
        "    sobel = cv2.Sobel(gray, cv2.CV_64F, isX, 1-isX)\n",
        "    abs_sobel = np.absolute(sobel)\n",
        "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel)) \n",
        "    grad_binary = np.zeros_like(scaled_sobel)\n",
        "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
        "    return grad_binary\n",
        "\n",
        "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
        "    abs_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
        "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel)) \n",
        "    mag_binary = np.zeros_like(scaled_sobel)\n",
        "    mag_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
        "    return mag_binary\n",
        "\n",
        "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
        "    abs_sobelx = np.absolute(sobelx)\n",
        "    abs_sobely = np.absolute(sobely)\n",
        "    grad_dir = np.arctan2(abs_sobely, abs_sobelx)\n",
        "    dir_binary = np.zeros_like(grad_dir)\n",
        "    dir_binary[(grad_dir >= thresh[0]) & (grad_dir <= thresh[1])] = 1\n",
        "    return dir_binary\n",
        "\n",
        "def apply_thresholds(image, ksize=3):\n",
        "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(10, 100))#(20, 100)\n",
        "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(10, 100))\n",
        "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
        "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
        "\n",
        "    combined = np.zeros_like(dir_binary)\n",
        "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
        "    \n",
        "    return combined\n",
        "\n",
        "\n",
        "def apply_color_threshold(image):\n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "    s_channel = hls[:,:,2]\n",
        "    s_thresh_min = 170\n",
        "    s_thresh_max = 255\n",
        "    s_binary = np.zeros_like(s_channel)\n",
        "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
        "    return s_binary\n",
        "\n",
        "\n",
        "def combine_threshold(s_binary, combined):\n",
        "    combined_binary = np.zeros_like(combined)\n",
        "    combined_binary[(s_binary == 1) |(s_binary == 255) | (combined == 1) |(combined == 255)] = 1\n",
        "    return combined_binary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7WY4V-bu3z4"
      },
      "outputs": [],
      "source": [
        "def threshold_rel(img, lo, hi):\n",
        "    vmin = np.min(img)\n",
        "    vmax = np.max(img)\n",
        "    \n",
        "    vlo = vmin + (vmax - vmin) * lo\n",
        "    vhi = vmin + (vmax - vmin) * hi\n",
        "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
        "\n",
        "def threshold_abs(img, lo, hi):\n",
        "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
        "\n",
        "def forward(img):\n",
        "      \"\"\" Take an image and extract all relavant pixels.\n",
        "      Parameters:\n",
        "          img (np.array): Input image\n",
        "      Returns:\n",
        "          binary (np.array): A binary image represent all positions of relavant pixels.\n",
        "      \"\"\"\n",
        "      hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
        "      hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "      h_channel = hls[:,:,0]\n",
        "      l_channel = hls[:,:,1]\n",
        "      s_channel = hls[:,:,2]\n",
        "      v_channel = hsv[:,:,2]\n",
        "\n",
        "      right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
        "      right_lane[:,:750] = 0\n",
        "\n",
        "      left_lane = threshold_abs(h_channel, 20, 30)\n",
        "      left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
        "      left_lane[:,550:] = 0\n",
        "\n",
        "      img2 = left_lane | right_lane\n",
        "\n",
        "      return img2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_jYEY-jftqV"
      },
      "source": [
        "## cocatenate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_RzjyLTfy4m"
      },
      "outputs": [],
      "source": [
        "\n",
        "def combine_images( lane_area_img1, edges, warp,warp_rect,warp_highlight, lane):        \n",
        "        \n",
        "        background = np.zeros_like(lane_area_img1)\n",
        "        large_img_size = (background.shape[1] - int(background.shape[1]/3),int(0.75*background.shape[0])) \n",
        "        small_img_size=(int(background.shape[1]/3),int(0.25*background.shape[0]))\n",
        "        small_img_x_offset=0 \n",
        "        small_img_y_offset=0\n",
        "        x=int((0.75*background.shape[0])/2)\n",
        "        new_image=(int(background.shape[1]/3),x)\n",
        "\n",
        "        warp_img = cv2.resize(np.dstack((warp, warp, warp))*255,small_img_size)\n",
        "        edges_image = cv2.resize(np.dstack((edges, edges, edges))*255,small_img_size)\n",
        "        lane_img = cv2.resize(lane,new_image)\n",
        "        road = cv2.resize(lane_area_img1,large_img_size)\n",
        "        warp_rect_img = cv2.resize(warp_rect,small_img_size)\n",
        "        warp_highlight_img = cv2.resize(warp_highlight,new_image)\n",
        "\n",
        "        background[0: small_img_size[1], 0: small_img_size[0]] = edges_image\n",
        "        \n",
        "        start_offset_y = small_img_y_offset \n",
        "        endy = start_offset_y + small_img_size[1]\n",
        "        if endy > background.shape[0]:\n",
        "          endy = background.shape[0]\n",
        "        start_offset_x = 2 * small_img_x_offset + small_img_size[0]\n",
        "        endx = start_offset_x + small_img_size[0]\n",
        "        if endx > background.shape[1]:\n",
        "          endx = background.shape[1]\n",
        "        background[start_offset_y:endy , start_offset_x: endx] = warp_img\n",
        "        \n",
        "        start_offset_y = small_img_y_offset \n",
        "        endy = start_offset_y + small_img_size[1]\n",
        "        if endy > background.shape[0]:\n",
        "          endy = background.shape[0]\n",
        "        start_offset_x = 3 * small_img_x_offset + 2 * small_img_size[0]\n",
        "        endx = start_offset_x + small_img_size[0]\n",
        "        if endx > background.shape[1]:\n",
        "          endx = background.shape[1]\n",
        "        background[start_offset_y: endy, start_offset_x: endx] = warp_rect_img\n",
        "\n",
        "        start_offset_y = small_img_y_offset \n",
        "        endy = x +int(0.25*background.shape[0])\n",
        "        if endy > background.shape[0]:\n",
        "          endy = background.shape[0]\n",
        "        # start_offset_x = 3 * small_img_x_offset + 3 * small_img_size[0]\n",
        "        # endx = start_offset_x + small_img_size[0]\n",
        "        if endx > background.shape[1]:\n",
        "          endx = background.shape[1]\n",
        "        background[int(0.25*background.shape[0]): endy, background.shape[1] - int(background.shape[1]/3): ] = warp_highlight_img\n",
        "        background[endy: , background.shape[1] - int(background.shape[1]/3): ] = lane_img\n",
        "        background[int(0.25*background.shape[0]):  , 0:background.shape[1] - int(background.shape[1]/3)  ] = road\n",
        "        \n",
        "        \n",
        "        return background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4_JK_tHeDqK"
      },
      "source": [
        "## process7_debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B8QISXkeIDy"
      },
      "outputs": [],
      "source": [
        "def process7_debug(input):\n",
        " \n",
        "    # step 1 get edges\n",
        "    warped=perspective_warp(input)\n",
        "\n",
        "    after_canny=canny(input)\n",
        "    # blur = cv2.blur(input,(5,5))\n",
        "    # gradient_combined = apply_thresholds(blur) #input\n",
        "    # # Color thresholding\n",
        "    # s_binary = apply_color_threshold(blur) #input\n",
        "    # # Combine Gradient and Color thresholding\n",
        "    # combined_binary = combine_threshold(s_binary, gradient_combined)\n",
        "    # combined = combine_threshold(after_canny,combined_binary)\n",
        "    # # step 2 warp canny image\n",
        "\n",
        "    # after_warp1=perspective_warp(combined)\n",
        "    # after_warp2 = remove_noise(after_warp1)\n",
        "\n",
        "    \n",
        "    after_warp=forward(warped)\n",
        "    rect = Draw_rectangle(after_warp)\n",
        "    inv_rect =inv_perspective_warp(rect) \n",
        "\n",
        "    # step 3 paint area between lanes\n",
        "\n",
        "    paint,left_curverad, right_curverad,center_diff= search_around_poly(after_warp)\n",
        "\n",
        "    # step 4 inverse perspective\n",
        "    frame =inv_perspective_warp(paint, \n",
        "                        dst_size=(input.shape[1],input.shape[0]),\n",
        "                        src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
        "                        dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]))\n",
        "\n",
        "\n",
        "    # step 5 add painting to input image\n",
        "    result = cv2.addWeighted(frame, 0.3, input, 0.7, 0,dtype = cv2.CV_8U) \n",
        "    curverad= (left_curverad + right_curverad)/2\n",
        "    side_pos = 'right'\n",
        "    if center_diff <= 0:\n",
        "        side_pos = 'left'\n",
        "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "    out = combine_images(result, after_canny, after_warp, rect, paint, inv_rect) # after_canny, after_warp,input must be binary\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfTnSheNqx9R"
      },
      "outputs": [],
      "source": [
        "# input=plt.imread(\"/content/drive/MyDrive/test_images/challange_img.jpg\")\n",
        "# out = process7_debug(input)\n",
        "# plt_images(input,\"input\",out,\"output\")\n",
        "# Input_video_path='/content/drive/MyDrive/test_images/project_video.mp4'\n",
        "# Output_video_path='video_tharwat.mp4'\n",
        "# clip1 = VideoFileClip(Input_video_path)\n",
        "# video_clip = clip1.fl_image(process7_debug) \n",
        "# video_clip.write_videofile(Output_video_path, audio=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEN7_RiO2RSU"
      },
      "source": [
        "## process7_no_debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWIYlUwx2Tmy"
      },
      "outputs": [],
      "source": [
        "def process7_debug(input):\n",
        " \n",
        "    # step 1 get edges\n",
        "    warped=perspective_warp(input)\n",
        "    after_canny=canny(input)\n",
        "    after_warp=forward(warped)\n",
        "    rect = Draw_rectangle(after_warp)\n",
        "    inv_rect =inv_perspective_warp(rect) \n",
        "\n",
        "    # step 3 paint area between lanes\n",
        "\n",
        "    paint,left_curverad, right_curverad,center_diff= search_around_poly(after_warp)\n",
        "\n",
        "    # step 4 inverse perspective\n",
        "    frame =inv_perspective_warp(paint, \n",
        "                        dst_size=(input.shape[1],input.shape[0]),\n",
        "                        src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
        "                        dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]))\n",
        "\n",
        "\n",
        "    # step 5 add painting to input image\n",
        "    result = cv2.addWeighted(frame, 0.3, input, 0.7, 0,dtype = cv2.CV_8U) \n",
        "    curverad= (left_curverad + right_curverad)/2\n",
        "    side_pos = 'right'\n",
        "    if center_diff <= 0:\n",
        "        side_pos = 'left'\n",
        "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
        "    # out = combine_images(result, after_canny, after_warp, rect, paint, inv_rect) # after_canny, after_warp,input must be binary\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4v95VznclvF"
      },
      "source": [
        "## to process a video and save the output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwG3CVS90-7a"
      },
      "outputs": [],
      "source": [
        "def create_video(Input_video_path,Output_video_path,mode):\n",
        "  clip1 = VideoFileClip(Input_video_path)\n",
        "  if (mode==1):\n",
        "    video_clip = clip1.fl_image(process7_debug) \n",
        "    video_clip.write_videofile(Output_video_path, audio=False)\n",
        "  else:\n",
        "    video_clip = clip1.fl_image(process7) \n",
        "    video_clip.write_videofile(Output_video_path, audio=False)\n",
        "\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GE15IzxDeN2u",
        "outputId": "03066599-8c22-4fb2-9099-65262f74e404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (5.6.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert) (2.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.0.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.1.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (2.11.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert) (4.9.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (5.7.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (4.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (4.11.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.4->nbconvert) (3.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QJP1X5oteRJY",
        "outputId": "2c08eab1-12df-4c9d-a202-1659e858a689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'last_version.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            `Exporter` class\n",
            "    Default: 'html'\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the \n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current \n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy \n",
            "            of reveal.js. \n",
            "            For speaker notes to work, this must be a relative path to a local \n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb\n",
            "\n",
            "            which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "\n",
            "            You can specify the export format with `--to`.\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "            can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of \n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to html last_version.ipynb\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Js3K-0dTOmoP",
        "kDLARzI7N8yc",
        "rtDHEimfQUbE",
        "E55SYwS559Yz",
        "Ujhl6bmYv5VP",
        "VeMTikUFiZ5O",
        "V69TyzE1U401",
        "N_jYEY-jftqV",
        "hEN7_RiO2RSU"
      ],
      "name": "last_version.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}